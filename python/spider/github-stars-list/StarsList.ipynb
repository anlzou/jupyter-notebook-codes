{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:30:26.055258Z",
     "start_time": "2020-09-01T15:30:25.876592Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests_html import HTMLSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T11:12:34.299816Z",
     "start_time": "2020-09-01T11:12:25.899123Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'accept-encoding': 'gzip, deflate, br',\n",
    "    'accept-language': 'zh-CN,zh;q=0.9',\n",
    "    'cache-control': 'no-cache',\n",
    "    'pragma': 'no-cache',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-site': 'same-site',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36',\n",
    "\n",
    "}\n",
    "\n",
    "def get_title_and_text(pages_next):\n",
    "    if pages_next == 1\n",
    "    \n",
    "\n",
    "def run(username):\n",
    "    stars_url = \"https://github.com/\" + username + \"?tab=stars\"\n",
    "    \n",
    "    session = HTMLSession()\n",
    "    resp = session.get(stars_url, headers=headers)\n",
    "    \n",
    "    # 获取类型\n",
    "    types = resp.html.xpath('//ul[@class=\"filter-list\"]/li/a/text()')\n",
    "    types_result = [k.replace(\"  \",\"\") for k in [j.replace(\"\\n      \",\"\") for j in [i.replace(\"\\n        \",\"\") for i in types]]]\n",
    "    types_result = types_result[4:] # 去掉多余\n",
    "#     print(types_result)\n",
    "    \n",
    "    # 获取类型链接\n",
    "    urls = resp.html.xpath('//ul[@class=\"filter-list\"]/li/a/@href')\n",
    "    urls_result = urls[4:] # 去掉多余\n",
    "#     print(urls_result)\n",
    "    \n",
    "    github_url = \"https://github.com\"\n",
    "    list_title = []\n",
    "    list_title_url = []\n",
    "    list_text = []\n",
    "    # 每个类型的页面\n",
    "    for url in urls_result:\n",
    "        resp = session.get(url, headers=headers)\n",
    "        pages_up_down = resp.html.xpath('//div[@class=\"BtnGroup\"]/a[@rel=\"nofollow\"]/@href')\n",
    "#         print(pages_up_down)\n",
    "        if len(pages_up_down) == 0:\n",
    "            title = resp.html.xpath('//div[@class=\"d-inline-block mb-1\"]/h3/a/@href')\n",
    "            title_url = [github_url + i for i in title]\n",
    "#             print(title)\n",
    "#             print(title_url)\n",
    "            text = resp.html.xpath('//div[@class=\"py-1\"]/p/text()')\n",
    "            text = [j.replace(\"\\n      \",\"\") for j in [i.replace(\"\\n        \",\"\") for i in text]]\n",
    "#             print(text)\n",
    "\n",
    "        elif len(pages_up_down) == 1:\n",
    "            resp = session.get(pages_up_down[0], headers=headers)\n",
    "            pages_up_down = resp.html.xpath('//div[@class=\"BtnGroup\"]/a[@rel=\"nofollow\"]/@href')\n",
    "#             print(pages_up_down)\n",
    "\n",
    "            title = resp.html.xpath('//div[@class=\"d-inline-block mb-1\"]/h3/a/@href')\n",
    "            title_url = [github_url + i for i in title]\n",
    "#             print(title)\n",
    "#             print(title_url)\n",
    "            text = resp.html.xpath('//div[@class=\"py-1\"]/p/text()')\n",
    "            text = [j.replace(\"\\n      \",\"\") for j in [i.replace(\"\\n        \",\"\") for i in text]]\n",
    "#             print(text)\n",
    "            \n",
    "            if len(pages_up_down[1]) != 0:\n",
    "                resp = session.get(pages_up_down[1], headers=headers)\n",
    "                pages_up_down = resp.html.xpath('//div[@class=\"BtnGroup\"]/a[@rel=\"nofollow\"]/@href')\n",
    "#                 print(pages_up_down)\n",
    "                \n",
    "                title = resp.html.xpath('//div[@class=\"d-inline-block mb-1\"]/h3/a/@href')\n",
    "                title_url = [github_url + i for i in title]\n",
    "#                 print(title)\n",
    "#                 print(title_url)\n",
    "                text = resp.html.xpath('//div[@class=\"py-1\"]/p/text()')\n",
    "                text = [j.replace(\"\\n      \",\"\") for j in [i.replace(\"\\n        \",\"\") for i in text]]\n",
    "#                 print(text)\n",
    "                \n",
    "                while len(pages_up_down[1]) != 0:\n",
    "                    resp = session.get(pages_up_down[1], headers=headers)\n",
    "                    pages_up_down = resp.html.xpath('//div[@class=\"BtnGroup\"]/a[@rel=\"nofollow\"]/@href')\n",
    "#                     print(pages_up_down)\n",
    "                    \n",
    "                    title = resp.html.xpath('//div[@class=\"d-inline-block mb-1\"]/h3/a/@href')\n",
    "                    title_url = [github_url + i for i in title]\n",
    "#                     print(title)\n",
    "#                     print(title_url)\n",
    "                    text = resp.html.xpath('//div[@class=\"py-1\"]/p/text()')\n",
    "                    text = [j.replace(\"\\n      \",\"\") for j in [i.replace(\"\\n        \",\"\") for i in text]]\n",
    "#                     print(text)\n",
    "        \n",
    "        list_title.append(title)\n",
    "        list_title_url.append(title_url)\n",
    "        list_text.append(text)\n",
    "    print(list_title)\n",
    "    print(list_title_url)\n",
    "    print(list_text)\n",
    "    \n",
    "    # 获取项目名称、评论、stars、fork\n",
    "    # 判断是否有下一页，获取链接\n",
    "    \n",
    "def makeMarkdown():\n",
    "    details_head_contents = \"<details><summary>Contents</summary>\"\n",
    "    details_head_List = \"<details><summary>List</summary>\"\n",
    "    datails_font = \"</details>\"\n",
    "    \n",
    "    # 模板制作：显示样式，是否需要stars&fork\n",
    "    # 支持输入文件名，可有可无\".md\"\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "#     username = input(\"input your github username: \")\n",
    "    username = \"halfrost\"\n",
    "    data = run(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T14:15:42.583908Z",
     "start_time": "2020-09-01T14:13:32.929323Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'accept-encoding': 'gzip, deflate, br',\n",
    "    'accept-language': 'zh-CN,zh;q=0.9',\n",
    "    'cache-control': 'no-cache',\n",
    "    'pragma': 'no-cache',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-site': 'same-site',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36',\n",
    "\n",
    "}\n",
    "\n",
    "github_url = \"https://github.com\"\n",
    "list_title = []\n",
    "list_title_url = []\n",
    "list_text = []\n",
    "def get_title_and_text(resp, pages_next):\n",
    "    button = resp.html.xpath('//div[@class=\"BtnGroup\"]/a[@rel=\"nofollow\"]/text()')\n",
    "#     print(button)\n",
    "    if len(pages_next) == 0 or (len(pages_next) == 1 and button[0] == \"Next\"):\n",
    "        title = resp.html.xpath('//div[@class=\"d-inline-block mb-1\"]/h3/a/@href')\n",
    "        title_url = [github_url + i for i in title]\n",
    "        text = resp.html.xpath('//div[@class=\"py-1\"]/p/text()')\n",
    "        text = [j.replace(\"\\n      \",\"\") for j in [i.replace(\"\\n        \",\"\") for i in text]]\n",
    "        \n",
    "        list_title.append(title)\n",
    "        list_title_url.append(title_url)\n",
    "        list_text.append(text)\n",
    "        \n",
    "        return list_title,list_title_url,list_text\n",
    "        \n",
    "    elif len(pages_next) == 2:\n",
    "        title = resp.html.xpath('//div[@class=\"d-inline-block mb-1\"]/h3/a/@href')\n",
    "        title_url = [github_url + i for i in title]\n",
    "        text = resp.html.xpath('//div[@class=\"py-1\"]/p/text()')\n",
    "        text = [j.replace(\"\\n      \",\"\") for j in [i.replace(\"\\n        \",\"\") for i in text]]\n",
    "        \n",
    "        list_title.append(title)\n",
    "        list_title_url.append(title_url)\n",
    "        list_text.append(text)\n",
    "        \n",
    "        resp = session.get(pages_next[1], headers=headers)\n",
    "        pages_next = resp.html.xpath('//div[@class=\"BtnGroup\"]/a[@rel=\"nofollow\"]/@href')\n",
    "        get_title_and_text(resp, pages_next)\n",
    "        \n",
    "    \n",
    "\n",
    "def run(username):\n",
    "    stars_url = \"https://github.com/\" + username + \"?tab=stars\"\n",
    "    session = HTMLSession()\n",
    "    resp = session.get(stars_url, headers=headers)\n",
    "    \n",
    "    # 获取类型\n",
    "    types = resp.html.xpath('//ul[@class=\"filter-list\"]/li/a/text()')\n",
    "    types_result = [k.replace(\"  \",\"\") for k in [j.replace(\"\\n      \",\"\") for j in [i.replace(\"\\n        \",\"\") for i in types]]]\n",
    "    types_result = types_result[4:] # 去掉多余\n",
    "#     print(types_result)\n",
    "    \n",
    "    # 获取类型链接\n",
    "    urls = resp.html.xpath('//ul[@class=\"filter-list\"]/li/a/@href')\n",
    "    urls_result = urls[4:] # 去掉多余\n",
    "    print(urls_result)\n",
    "    \n",
    "    list_title = []\n",
    "    list_title_url = []\n",
    "    list_text = []\n",
    "    # 每个类型的页面\n",
    "    for url in urls_result:\n",
    "        resp = session.get(url, headers=headers)\n",
    "        pages_next = resp.html.xpath('//div[@class=\"BtnGroup\"]/a[@rel=\"nofollow\"]/@href')\n",
    "#         type_data = get_title_and_text(resp, pages_next)\n",
    "        \n",
    "#         list_title.append(type_data[0])\n",
    "#         list_title_url.append(type_data[1])\n",
    "#         list_text.append(type_data[2])\n",
    "\n",
    "#     print(list_title)\n",
    "#     print(list_title_url)\n",
    "#     print(list_text)\n",
    "    \n",
    "    # 获取项目名称、评论、stars、fork\n",
    "    # 判断是否有下一页，获取链接\n",
    "    \n",
    "def makeMarkdown():\n",
    "    details_head_contents = \"<details><summary>Contents</summary>\"\n",
    "    details_head_List = \"<details><summary>List</summary>\"\n",
    "    datails_font = \"</details>\"\n",
    "    \n",
    "    # 模板制作：显示样式，是否需要stars&fork\n",
    "    # 支持输入文件名，可有可无\".md\"\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "#     username = input(\"input your github username: \")\n",
    "    username = \"anlzou\"\n",
    "    data = run(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:56:52.934278Z",
     "start_time": "2020-09-01T15:56:50.666593Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d5c435940665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;31m#     username = input(\"input your github username: \")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0musername\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"anlzou\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-d5c435940665>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(username)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m#         print(list_title_result,list_title_url_result,list_text_result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_title\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_title_url\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'accept-encoding': 'gzip, deflate, br',\n",
    "    'accept-language': 'zh-CN,zh;q=0.9',\n",
    "    'cache-control': 'no-cache',\n",
    "    'pragma': 'no-cache',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-site': 'same-site',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36',\n",
    "}\n",
    "\n",
    "'''\n",
    "    data[0]:types\n",
    "    data[1]:types_url\n",
    "    data[2]:title_result\n",
    "    data[3]:title_url_result\n",
    "    data[4]:text_result\n",
    "'''\n",
    "data = []\n",
    "github_url = \"https://github.com\"\n",
    "session = HTMLSession()\n",
    "\n",
    "list_title = []\n",
    "list_title_url = []\n",
    "list_text = []\n",
    "\n",
    "def get_title_and_text(url):\n",
    "    resp = session.get(url, headers=headers)\n",
    "    url = resp.html.xpath('//div[@class=\"BtnGroup\"]/a[@rel=\"nofollow\"]/@href')\n",
    "    button = resp.html.xpath('//div[@class=\"BtnGroup\"]/a[@rel=\"nofollow\"]/text()')\n",
    "\n",
    "    if len(url) == 0 or (len(url) == 1 and button[0] == \"Next\"):\n",
    "        title = resp.html.xpath('//div[@class=\"d-inline-block mb-1\"]/h3/a/@href')\n",
    "        title_url = [github_url + i for i in title]\n",
    "        text = resp.html.xpath('//div[@class=\"py-1\"]/p/text()')\n",
    "        text = [j.replace(\"\\n      \",\"\") for j in [i.replace(\"\\n        \",\"\") for i in text]]\n",
    "        \n",
    "        list_title.append(title)\n",
    "        list_title_url.append(title_url)\n",
    "        list_text.append(text)\n",
    "        \n",
    "        return list_title,list_title_url,list_text\n",
    "        \n",
    "    elif len(pages_next) == 2:\n",
    "        title = resp.html.xpath('//div[@class=\"d-inline-block mb-1\"]/h3/a/@href')\n",
    "        title_url = [github_url + i for i in title]\n",
    "        text = resp.html.xpath('//div[@class=\"py-1\"]/p/text()')\n",
    "        text = [j.replace(\"\\n      \",\"\") for j in [i.replace(\"\\n        \",\"\") for i in text]]\n",
    "        \n",
    "        list_title.append(title)\n",
    "        list_title_url.append(title_url)\n",
    "        list_text.append(text)\n",
    "        \n",
    "        resp = session.get(pages_next[1], headers=headers)\n",
    "        pages_next = resp.html.xpath('//div[@class=\"BtnGroup\"]/a[@rel=\"nofollow\"]/@href')\n",
    "        get_title_and_text(resp)\n",
    "        \n",
    "def get_types(username):\n",
    "    stars_url = \"https://github.com/\" + username + \"?tab=stars\"\n",
    "    resp = session.get(stars_url, headers=headers)\n",
    "    \n",
    "    # 获取类型\n",
    "    types = resp.html.xpath('//ul[@class=\"filter-list\"]/li/a/text()')\n",
    "    types_result = [k.replace(\"  \",\"\") for k in [j.replace(\"\\n      \",\"\") for j in [i.replace(\"\\n        \",\"\") for i in types]]]\n",
    "    types_result = types_result[4:] # 去掉多余\n",
    "    \n",
    "    # 获取类型链接\n",
    "    urls = resp.html.xpath('//ul[@class=\"filter-list\"]/li/a/@href')\n",
    "    urls_result = urls[4:] # 去掉多余\n",
    "\n",
    "    return types_result,urls_result\n",
    "\n",
    "def run(username):\n",
    "    type_data = get_types(username)\n",
    "    for i in type_data:\n",
    "        data.append(i)\n",
    "        \n",
    "#     每个类型的页面\n",
    "    for url in data[1]:\n",
    "        list_title_result,list_title_url_result,list_text_result = get_title_and_text(url)\n",
    "#         print(list_title_result,list_title_url_result,list_text_result)\n",
    "        for i in list_title:\n",
    "            data[2].append(i)\n",
    "        for i in list_title_url:\n",
    "            data[3].append(i)\n",
    "        for i in list_text:\n",
    "            data[4].append(i)\n",
    "        \n",
    "        list_title.clear()\n",
    "        list_title_url.clear()\n",
    "        list_text.clear()\n",
    "        \n",
    "    for i in data:\n",
    "        print(i)\n",
    "    \n",
    "    # 获取项目名称、评论、stars、fork\n",
    "    # 判断是否有下一页，获取链接\n",
    "    \n",
    "def makeMarkdown():\n",
    "    details_head_contents = \"<details><summary>Contents</summary>\"\n",
    "    details_head_List = \"<details><summary>List</summary>\"\n",
    "    datails_font = \"</details>\"\n",
    "    \n",
    "    # 模板制作：显示样式，是否需要stars&fork\n",
    "    # 支持输入文件名，可有可无\".md\"\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "#     username = input(\"input your github username: \")\n",
    "    username = \"anlzou\"\n",
    "    run(username)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
